{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "response = urllib2.urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n",
    "data_file = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"adult.data\", \"wb\") as code:\n",
    "    code.write(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attempting to download:', 'data.data')\n",
      "0%.\n",
      "Download Complete!\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to verify /Users/jiqiyang/Documents/CS/AI/Week1/data.data. Can you get to it with a browser?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-57b87fb6d619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdest_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3974305\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-57b87fb6d619>\u001b[0m in \u001b[0;36mmaybe_download\u001b[0;34m(filename, expected_bytes, force)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     raise Exception(\n\u001b[0;32m---> 38\u001b[0;31m       'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdest_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to verify /Users/jiqiyang/Documents/CS/AI/Week1/data.data. Can you get to it with a browser?"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "last_percent_reported = None\n",
    "# data_root = '.' # Change me to store data elsewhere\n",
    "data_root = '/Users/jiqiyang/Documents/CS/AI/Week1'\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('data.data', 3974305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(\".\")      \n",
    "for filename in files:\n",
    "    portion = os.path.splitext(filename)\n",
    "    if portion[1] == \".data\":   \n",
    "        newname = portion[0] + \".csv\"   \n",
    "        os.rename(filename,newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardize using sklearn\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: United-States",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-53eb5d93f37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mstandardizedX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jiqiyang/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jiqiyang/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jiqiyang/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: United-States"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "\n",
    "print('\\nStandardize using sklearn')\n",
    "filename = 'adult.csv'\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "data_frame = read_csv(filename, names=names)\n",
    "array = data_frame.values\n",
    "\n",
    "# Separate array into input and output components\n",
    "X = array[:, 0:14]\n",
    "Y = array[:, 14]\n",
    "scaler = StandardScaler().fit(X)\n",
    "standardizedX = scaler.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(standardizedX[0:5, :])\n",
    "\n",
    "\n",
    "# -- Standardize from scratch -- #\n",
    "print('\\nStandardize from scratch')\n",
    "# -- Standardize from scratch -- #\n",
    "# Calculate data mean and standard deviation\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "\n",
    "# The values for each attribute now have a mean of 0 and standard deviation of 1\n",
    "X_scaled = (X - X_mean) / X_std\n",
    "\n",
    "print(X_scaled[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15)\n"
     ]
    }
   ],
   "source": [
    "data_set = read_csv('./adult.csv', header=None, na_values=['?'], skipinitialspace=True, keep_default_na=True)\n",
    "\n",
    "#Drop the lines which has NaN values\n",
    "data_set.dropna(inplace=True)\n",
    "print(data_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30139, 15)\n",
      "                 0             2             4             10            11  \\\n",
      "count  30139.000000  3.013900e+04  30139.000000  30139.000000  30139.000000   \n",
      "mean      38.441720  1.897950e+05     10.122532   1092.841202     88.439928   \n",
      "std       13.131426  1.056586e+05      2.548738   7409.110596    404.445239   \n",
      "min       17.000000  1.376900e+04      1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.176275e+05      9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.784170e+05     10.000000      0.000000      0.000000   \n",
      "75%       47.000000  2.376045e+05     13.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06     16.000000  99999.000000   4356.000000   \n",
      "\n",
      "                 12  \n",
      "count  30139.000000  \n",
      "mean      40.934703  \n",
      "std       11.978753  \n",
      "min        1.000000  \n",
      "25%       40.000000  \n",
      "50%       40.000000  \n",
      "75%       45.000000  \n",
      "max       99.000000  \n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicated line\n",
    "data_set.drop_duplicates(inplace=True)\n",
    "print(data_set.shape)\n",
    "\n",
    "# The summary of this data\n",
    "print(data_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                 1       2          3   4                      5   \\\n",
      "0  39         State-gov   77516  Bachelors  13          Never-married   \n",
      "1  50  Self-emp-not-inc   83311  Bachelors  13     Married-civ-spouse   \n",
      "2  38           Private  215646    HS-grad   9               Divorced   \n",
      "3  53           Private  234721       11th   7     Married-civ-spouse   \n",
      "4  28           Private  338409  Bachelors  13     Married-civ-spouse   \n",
      "5  37           Private  284582    Masters  14     Married-civ-spouse   \n",
      "6  49           Private  160187        9th   5  Married-spouse-absent   \n",
      "7  52  Self-emp-not-inc  209642    HS-grad   9     Married-civ-spouse   \n",
      "8  31           Private   45781    Masters  14          Never-married   \n",
      "9  42           Private  159449  Bachelors  13     Married-civ-spouse   \n",
      "\n",
      "                  6              7      8       9      10  11  12  \\\n",
      "0       Adm-clerical  Not-in-family  White    Male   2174   0  40   \n",
      "1    Exec-managerial        Husband  White    Male      0   0  13   \n",
      "2  Handlers-cleaners  Not-in-family  White    Male      0   0  40   \n",
      "3  Handlers-cleaners        Husband  Black    Male      0   0  40   \n",
      "4     Prof-specialty           Wife  Black  Female      0   0  40   \n",
      "5    Exec-managerial           Wife  White  Female      0   0  40   \n",
      "6      Other-service  Not-in-family  Black  Female      0   0  16   \n",
      "7    Exec-managerial        Husband  White    Male      0   0  45   \n",
      "8     Prof-specialty  Not-in-family  White  Female  14084   0  50   \n",
      "9    Exec-managerial        Husband  White    Male   5178   0  40   \n",
      "\n",
      "              13     14  \n",
      "0  United-States  <=50K  \n",
      "1  United-States  <=50K  \n",
      "2  United-States  <=50K  \n",
      "3  United-States  <=50K  \n",
      "4           Cuba  <=50K  \n",
      "5  United-States  <=50K  \n",
      "6        Jamaica  <=50K  \n",
      "7  United-States   >50K  \n",
      "8  United-States   >50K  \n",
      "9  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "print(data_set.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "object\n",
      "int64\n",
      "object\n",
      "int64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "object\n",
      "object\n",
      "    0   1       2   3   4   5   6   7   8   9      10    11  12  13  14\n",
      "0   39   5   77516   9  13   4   0   1   4   1   2174     0  40  38   0\n",
      "1   50   4   83311   9  13   2   3   0   4   1      0     0  13  38   0\n",
      "2   38   2  215646  11   9   0   5   1   4   1      0     0  40  38   0\n",
      "3   53   2  234721   1   7   2   5   0   2   1      0     0  40  38   0\n",
      "4   28   2  338409   9  13   2   9   5   2   0      0     0  40   4   0\n",
      "5   37   2  284582  12  14   2   3   5   4   0      0     0  40  38   0\n",
      "6   49   2  160187   6   5   3   7   1   2   0      0     0  16  22   0\n",
      "7   52   4  209642  11   9   2   3   0   4   1      0     0  45  38   1\n",
      "8   31   2   45781  12  14   4   9   1   4   0  14084     0  50  38   1\n",
      "9   42   2  159449   9  13   2   3   0   4   1   5178     0  40  38   1\n",
      "10  37   2  280464  15  10   2   3   0   2   1      0     0  80  38   1\n",
      "11  30   5  141297   9  13   2   9   0   1   1      0     0  40  18   1\n",
      "12  23   2  122272   9  13   4   0   3   4   0      0     0  30  38   0\n",
      "13  32   2  205019   7  12   4  11   1   2   1      0     0  50  38   0\n",
      "15  34   2  245487   5   4   2  13   0   0   1      0     0  45  25   0\n",
      "16  25   4  176756  11   9   4   4   3   4   1      0     0  35  38   0\n",
      "17  32   2  186824  11   9   4   6   4   4   1      0     0  40  38   0\n",
      "18  38   2   28887   1   7   2  11   0   4   1      0     0  50  38   0\n",
      "19  43   4  292175  12  14   0   3   4   4   0      0     0  45  38   1\n",
      "20  40   2  193524  10  16   2   9   0   4   1      0     0  60  38   1\n",
      "21  54   2  302146  11   9   5   7   4   2   0      0     0  20  38   0\n",
      "22  35   0   76845   6   5   2   4   0   2   1      0     0  40  38   0\n",
      "23  43   2  117037   1   7   2  13   0   4   1      0  2042  40  38   0\n",
      "24  59   2  109015  11   9   0  12   4   4   0      0     0  40  38   0\n",
      "25  56   1  216851   9  13   2  12   0   4   1      0     0  40  38   1\n",
      "26  19   2  168294  11   9   4   2   3   4   1      0     0  40  38   0\n",
      "28  39   2  367260  11   9   0   3   1   4   1      0     0  80  38   0\n",
      "29  49   2  193366  11   9   2   2   0   4   1      0     0  40  38   0\n",
      "30  23   1  190709   7  12   4  10   1   4   1      0     0  52  38   0\n",
      "31  20   2  266015  15  10   4  11   3   2   1      0     0  44  38   0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Lable Encoding the feature values which is 'object' type\n",
    "le = LabelEncoder()\n",
    "for col in data_set.columns.values:\n",
    "    print(data_set[col].dtypes)\n",
    "    if data_set[col].dtypes == 'object':\n",
    "        le.fit(data_set[col].values)\n",
    "        data_set[col] = le.transform(data_set[col])\n",
    "        \n",
    "print(data_set.head(n=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to nparray\n",
    "data_set = data_set.as_matrix().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(24111, 13)\n",
      "y_train:(24111,)\n",
      "x_test:(6028, 13)\n",
      "y_test:(6028,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to Training data and Testing Data : 80% Training()  and 20% Testing ()\n",
    "x_train = data_set[0:24111, :-2]\n",
    "y_train = data_set[0:24111, -1]\n",
    "\n",
    "x_test = data_set[-6028:, :-2]\n",
    "y_test = data_set[-6028:, -1]\n",
    "\n",
    "print(\"x_train:\" + str(x_train.shape))\n",
    "print(\"y_train:\" + str(y_train.shape))\n",
    "print(\"x_test:\" + str(x_test.shape))\n",
    "print(\"y_test:\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized x_train:\n",
      "[[  5.02924039e-04   6.44774410e-05   9.99606663e-01   1.16059394e-04\n",
      "    1.67641346e-04   5.15819528e-05   0.00000000e+00   1.28954882e-05\n",
      "    5.15819528e-05   1.28954882e-05   2.80347913e-02   0.00000000e+00\n",
      "    5.15819528e-04]]\n",
      "Normalized x_test:\n",
      "[[  2.12685731e-04   9.66753324e-06   9.99999971e-01   5.31714328e-05\n",
      "    4.35038996e-05   1.93350665e-05   5.31714328e-05   9.66753324e-06\n",
      "    1.93350665e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    7.25064993e-05]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Normalize the training and testing data\n",
    "norm = Normalizer(norm='l2').fit(x_train)\n",
    "x_train = norm.transform(x_train)\n",
    "x_test = norm.transform(x_test)\n",
    "print(\"Normalized x_train:\\n\" + str(x_train[:1, :]))\n",
    "print(\"Normalized x_test:\\n\" + str(x_test[:1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78682813536828133"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# KNN clustering\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train, y_train)\n",
    "accuracy_score(y_test, knn.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.301  0.833  0.043  0.6    0.8    0.667  0.     0.2    1.     1.     0.022\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.452  0.667  0.047  0.6    0.8    0.333  0.231  0.     1.     1.     0.\n",
      "   0.     0.122  0.95 ]\n",
      " [ 0.288  0.333  0.137  0.733  0.533  0.     0.385  0.2    1.     1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.493  0.333  0.15   0.067  0.4    0.333  0.385  0.     0.5    1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.151  0.333  0.221  0.6    0.8    0.333  0.692  1.     0.5    0.     0.\n",
      "   0.     0.398  0.1  ]]\n",
      "\n",
      "Rescale from scratch\n",
      "[[ 0.301  0.833  0.043  0.6    0.8    0.667  0.     0.2    1.     1.     0.022\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.452  0.667  0.047  0.6    0.8    0.333  0.231  0.     1.     1.     0.\n",
      "   0.     0.122  0.95 ]\n",
      " [ 0.288  0.333  0.137  0.733  0.533  0.     0.385  0.2    1.     1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.493  0.333  0.15   0.067  0.4    0.333  0.385  0.     0.5    1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.151  0.333  0.221  0.6    0.8    0.333  0.692  1.     0.5    0.     0.\n",
      "   0.     0.398  0.1  ]]\n",
      "\n",
      " Simpler Way\n",
      "[[ 0.301  0.833  0.043  0.6    0.8    0.667  0.     0.2    1.     1.     0.022\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.452  0.667  0.047  0.6    0.8    0.333  0.231  0.     1.     1.     0.\n",
      "   0.     0.122  0.95 ]\n",
      " [ 0.288  0.333  0.137  0.733  0.533  0.     0.385  0.2    1.     1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.493  0.333  0.15   0.067  0.4    0.333  0.385  0.     0.5    1.     0.\n",
      "   0.     0.398  0.95 ]\n",
      " [ 0.151  0.333  0.221  0.6    0.8    0.333  0.692  1.     0.5    0.     0.\n",
      "   0.     0.398  0.1  ]]\n"
     ]
    }
   ],
   "source": [
    "# rescale data\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separate array into input and output components\n",
    "X = data_set[:, 0:14]\n",
    "Y = data_set[:, 14]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])\n",
    "\n",
    "\n",
    "# -- Rescale from scratch -- #\n",
    "print('\\nRescale from scratch')\n",
    "# -- Rescale from scratch -- #\n",
    "# Define scale range min and max\n",
    "MIN = 0\n",
    "MAX = 1\n",
    "\n",
    "# Calculate X min and max for each attribute\n",
    "# axis=0 calculates along each column\n",
    "X_min = np.min(X, axis=0)\n",
    "X_max = np.max(X, axis=0)\n",
    "\n",
    "# Calculate X_std and X_scaled\n",
    "X_std = (X - X_min) / (X_max - X_min)\n",
    "X_scaled = X_std * (MAX - MIN) + MIN\n",
    "\n",
    "print(X_scaled[0:5, :])\n",
    "print('\\n Simpler Way')\n",
    "\n",
    "# -- Simpler way to do it -- #\n",
    "X_std_2 = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled_2 = X_std_2 * (MAX - MIN) + MIN\n",
    "\n",
    "print(X_scaled_2[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.043  2.935 -1.063 -0.35   1.129  0.948 -1.479 -0.261  0.385  0.693\n",
      "   0.146 -0.219 -0.078  0.265]\n",
      " [ 0.88   1.887 -1.008 -0.35   1.129 -0.387 -0.735 -0.886  0.385  0.693\n",
      "  -0.148 -0.219 -2.332  0.265]\n",
      " [-0.034 -0.209  0.245  0.175 -0.44  -1.722 -0.238 -0.261  0.385  0.693\n",
      "  -0.148 -0.219 -0.078  0.265]\n",
      " [ 1.109 -0.209  0.425 -2.448 -1.225 -0.387 -0.238 -0.886 -2.011  0.693\n",
      "  -0.148 -0.219 -0.078  0.265]\n",
      " [-0.795 -0.209  1.407 -0.35   1.129 -0.387  0.754  2.236 -2.011 -1.444\n",
      "  -0.148 -0.219 -0.078 -5.307]]\n",
      "\n",
      "Standardize from scratch\n",
      "[[ 0.043  2.935 -1.063 -0.35   1.129  0.948 -1.479 -0.261  0.385  0.693\n",
      "   0.146 -0.219 -0.078  0.265]\n",
      " [ 0.88   1.887 -1.008 -0.35   1.129 -0.387 -0.735 -0.886  0.385  0.693\n",
      "  -0.148 -0.219 -2.332  0.265]\n",
      " [-0.034 -0.209  0.245  0.175 -0.44  -1.722 -0.238 -0.261  0.385  0.693\n",
      "  -0.148 -0.219 -0.078  0.265]\n",
      " [ 1.109 -0.209  0.425 -2.448 -1.225 -0.387 -0.238 -0.886 -2.011  0.693\n",
      "  -0.148 -0.219 -0.078  0.265]\n",
      " [-0.795 -0.209  1.407 -0.35   1.129 -0.387  0.754  2.236 -2.011 -1.444\n",
      "  -0.148 -0.219 -0.078 -5.307]]\n"
     ]
    }
   ],
   "source": [
    "# standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import set_printoptions\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "standardizedX = scaler.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(standardizedX[0:5, :])\n",
    "\n",
    "\n",
    "# -- Standardize from scratch -- #\n",
    "print('\\nStandardize from scratch')\n",
    "# -- Standardize from scratch -- #\n",
    "# Calculate data mean and standard deviation\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "\n",
    "# The values for each attribute now have a mean of 0 and standard deviation of 1\n",
    "X_scaled = (X - X_mean) / X_std\n",
    "\n",
    "print(X_scaled[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.885e-04   6.262e-05   9.708e-01   1.127e-04   1.628e-04   5.010e-05\n",
      "    0.000e+00   1.252e-05   5.010e-05   1.252e-05   2.723e-02   0.000e+00\n",
      "    5.010e-04   4.759e-04]\n",
      " [  5.992e-04   4.793e-05   9.984e-01   1.079e-04   1.558e-04   2.397e-05\n",
      "    3.595e-05   0.000e+00   4.793e-05   1.198e-05   0.000e+00   0.000e+00\n",
      "    1.558e-04   4.554e-04]\n",
      " [  1.761e-04   9.268e-06   9.993e-01   5.097e-05   4.171e-05   0.000e+00\n",
      "    2.317e-05   4.634e-06   1.854e-05   4.634e-06   0.000e+00   0.000e+00\n",
      "    1.854e-04   1.761e-04]\n",
      " [  2.257e-04   8.515e-06   9.994e-01   4.258e-06   2.980e-05   8.515e-06\n",
      "    2.129e-05   0.000e+00   8.515e-06   4.258e-06   0.000e+00   0.000e+00\n",
      "    1.703e-04   1.618e-04]\n",
      " [  8.271e-05   5.908e-06   9.997e-01   2.659e-05   3.840e-05   5.908e-06\n",
      "    2.659e-05   1.477e-05   5.908e-06   0.000e+00   0.000e+00   0.000e+00\n",
      "    1.182e-04   1.182e-05]]\n",
      "\n",
      "Normalize from scratch--L1 norm\n",
      "[[  4.885e-04   6.262e-05   9.708e-01   1.127e-04   1.628e-04   5.010e-05\n",
      "    0.000e+00   1.252e-05   5.010e-05   1.252e-05   2.723e-02   0.000e+00\n",
      "    5.010e-04   4.759e-04]\n",
      " [  5.992e-04   4.793e-05   9.984e-01   1.079e-04   1.558e-04   2.397e-05\n",
      "    3.595e-05   0.000e+00   4.793e-05   1.198e-05   0.000e+00   0.000e+00\n",
      "    1.558e-04   4.554e-04]\n",
      " [  1.761e-04   9.268e-06   9.993e-01   5.097e-05   4.171e-05   0.000e+00\n",
      "    2.317e-05   4.634e-06   1.854e-05   4.634e-06   0.000e+00   0.000e+00\n",
      "    1.854e-04   1.761e-04]\n",
      " [  2.257e-04   8.515e-06   9.994e-01   4.258e-06   2.980e-05   8.515e-06\n",
      "    2.129e-05   0.000e+00   8.515e-06   4.258e-06   0.000e+00   0.000e+00\n",
      "    1.703e-04   1.618e-04]\n",
      " [  8.271e-05   5.908e-06   9.997e-01   2.659e-05   3.840e-05   5.908e-06\n",
      "    2.659e-05   1.477e-05   5.908e-06   0.000e+00   0.000e+00   0.000e+00\n",
      "    1.182e-04   1.182e-05]]\n",
      "\n",
      "Normalize using sklearn--L2 norm\n",
      "[[  5.029e-04   6.448e-05   9.996e-01   1.161e-04   1.676e-04   5.158e-05\n",
      "    0.000e+00   1.290e-05   5.158e-05   1.290e-05   2.803e-02   0.000e+00\n",
      "    5.158e-04   4.900e-04]\n",
      " [  6.002e-04   4.801e-05   1.000e+00   1.080e-04   1.560e-04   2.401e-05\n",
      "    3.601e-05   0.000e+00   4.801e-05   1.200e-05   0.000e+00   0.000e+00\n",
      "    1.560e-04   4.561e-04]\n",
      " [  1.762e-04   9.274e-06   1.000e+00   5.101e-05   4.174e-05   0.000e+00\n",
      "    2.319e-05   4.637e-06   1.855e-05   4.637e-06   0.000e+00   0.000e+00\n",
      "    1.855e-04   1.762e-04]\n",
      " [  2.258e-04   8.521e-06   1.000e+00   4.260e-06   2.982e-05   8.521e-06\n",
      "    2.130e-05   0.000e+00   8.521e-06   4.260e-06   0.000e+00   0.000e+00\n",
      "    1.704e-04   1.619e-04]\n",
      " [  8.274e-05   5.910e-06   1.000e+00   2.660e-05   3.842e-05   5.910e-06\n",
      "    2.660e-05   1.478e-05   5.910e-06   0.000e+00   0.000e+00   0.000e+00\n",
      "    1.182e-04   1.182e-05]]\n",
      "\n",
      "Normalize from scratch--L2 norm\n",
      "[[  5.029e-04   6.448e-05   9.996e-01   1.161e-04   1.676e-04   5.158e-05\n",
      "    0.000e+00   1.290e-05   5.158e-05   1.290e-05   2.803e-02   0.000e+00\n",
      "    5.158e-04   4.900e-04]\n",
      " [  6.002e-04   4.801e-05   1.000e+00   1.080e-04   1.560e-04   2.401e-05\n",
      "    3.601e-05   0.000e+00   4.801e-05   1.200e-05   0.000e+00   0.000e+00\n",
      "    1.560e-04   4.561e-04]\n",
      " [  1.762e-04   9.274e-06   1.000e+00   5.101e-05   4.174e-05   0.000e+00\n",
      "    2.319e-05   4.637e-06   1.855e-05   4.637e-06   0.000e+00   0.000e+00\n",
      "    1.855e-04   1.762e-04]\n",
      " [  2.258e-04   8.521e-06   1.000e+00   4.260e-06   2.982e-05   8.521e-06\n",
      "    2.130e-05   0.000e+00   8.521e-06   4.260e-06   0.000e+00   0.000e+00\n",
      "    1.704e-04   1.619e-04]\n",
      " [  8.274e-05   5.910e-06   1.000e+00   2.660e-05   3.842e-05   5.910e-06\n",
      "    2.660e-05   1.478e-05   5.910e-06   0.000e+00   0.000e+00   0.000e+00\n",
      "    1.182e-04   1.182e-05]]\n"
     ]
    }
   ],
   "source": [
    "# normalize_data\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# L1 norm\n",
    "scaler = Normalizer(norm='l1').fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5, :])\n",
    "\n",
    "\n",
    "# -- Normalize from scratch--L1 norm -- #\n",
    "# L1 norm\n",
    "print('\\nNormalize from scratch--L1 norm')\n",
    "norms = np.abs(X).sum(axis=1)\n",
    "\n",
    "X_normalized = X / norms[:, np.newaxis]\n",
    "\n",
    "print(X_normalized[0:5, :])\n",
    "\n",
    "# -- Normalize using sklearn--L2 norm -- #\n",
    "# L2 norm\n",
    "print('\\nNormalize using sklearn--L2 norm')\n",
    "scaler = Normalizer(norm='l2').fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5, :])\n",
    "\n",
    "# -- Normalize from scratch--L2 norm -- #\n",
    "# L2 norm\n",
    "print('\\nNormalize from scratch--L2 norm')\n",
    "norms = np.einsum('ij,ij->i', X, X)\n",
    "np.sqrt(norms, norms)\n",
    "X_normalized = X / norms[:, np.newaxis]\n",
    "print(X_normalized[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.]]\n",
      "\n",
      "Binarize from scratch\n",
      "[[ 1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# binarize data\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5, :])\n",
    "\n",
    "# -- Binarize from scratch -- #\n",
    "print('\\nBinarize from scratch')\n",
    "threshold = 0.0\n",
    "cond = X > threshold\n",
    "not_cond = np.logical_not(cond)\n",
    "X_binarized = X\n",
    "X_binarized[cond] = 1\n",
    "X_binarized[not_cond] = 0\n",
    "\n",
    "print(X_binarized[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
